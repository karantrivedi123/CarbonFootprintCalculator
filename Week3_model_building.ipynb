{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd9e329a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n",
      "‚úÖ Dataset loaded successfully with 11000 rows.\n",
      "Separated data: 7700 rows for training, 3300 rows for prediction.\n",
      "\n",
      "‚úÖ Model training complete!\n",
      "‚úÖ Predicted emissions for 3300 companies.\n",
      "‚úÖ Missing values have been filled with predictions.\n",
      "\n",
      "--- Verification ---\n",
      "üéâ Success! There are now 0 missing carbon emission values.\n",
      "‚úÖ Final, completed dataset saved to 'companies_with_full_emissions_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# --- Part 1: Import Libraries and Load Data ---\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "\n",
    "try:\n",
    "    # Use the file with artificially missing data\n",
    "    df = pd.read_csv('dataset_with_missing_emissions.csv')\n",
    "    print(f\"‚úÖ Dataset loaded successfully with {len(df)} rows.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: Make sure 'dataset_with_missing_emissions.csv' is in your CarbonProject folder.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- Part 2: Prepare Data by Separating Known and Unknown Emissions ---\n",
    "\n",
    "# üí° NEW LOGIC: Separate the dataframe into two parts.\n",
    "# One part for training (where we know the emissions)\n",
    "train_df = df.dropna(subset=['CarbonEmissions']).copy()\n",
    "\n",
    "# Another part for predicting (where emissions are missing)\n",
    "predict_df = df[df['CarbonEmissions'].isnull()].copy()\n",
    "\n",
    "print(f\"Separated data: {len(train_df)} rows for training, {len(predict_df)} rows for prediction.\")\n",
    "\n",
    "\n",
    "# --- Part 3: Prepare and Train the Model ---\n",
    "\n",
    "# One-Hot Encode the 'Industry' column for the training data\n",
    "train_df_processed = pd.get_dummies(train_df, columns=['Industry'], drop_first=True)\n",
    "\n",
    "# Define our features (X) and the target we want to predict (y)\n",
    "features = ['Revenue'] + [col for col in train_df_processed.columns if 'Industry_' in col]\n",
    "target = 'CarbonEmissions'\n",
    "\n",
    "# Create the training sets X and y\n",
    "X_train = train_df_processed[features]\n",
    "y_train = train_df_processed[target]\n",
    "\n",
    "# Initialize and train the Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n‚úÖ Model training complete!\")\n",
    "\n",
    "\n",
    "# --- Part 4: Prepare Prediction Data and Predict Missing Values ---\n",
    "\n",
    "# One-Hot Encode the prediction data just like we did for the training data\n",
    "predict_df_processed = pd.get_dummies(predict_df, columns=['Industry'], drop_first=True)\n",
    "\n",
    "# Align the columns of the prediction data with the training data.\n",
    "# This ensures both have the exact same 'Industry' columns.\n",
    "X_predict_aligned, _ = predict_df_processed.align(X_train, join='right', axis=1, fill_value=0)\n",
    "X_predict_aligned = X_predict_aligned[features] # Ensure column order is the same\n",
    "\n",
    "# Use our trained model to PREDICT the emissions\n",
    "predicted_emissions = model.predict(X_predict_aligned)\n",
    "\n",
    "print(f\"‚úÖ Predicted emissions for {len(predicted_emissions)} companies.\")\n",
    "\n",
    "\n",
    "# --- Part 5: Fill in the Missing Values ---\n",
    "\n",
    "# Put the predictions back into our prediction dataframe\n",
    "predict_df['CarbonEmissions'] = predicted_emissions\n",
    "\n",
    "# Combine the original training data and the now-completed prediction data\n",
    "final_df = pd.concat([train_df, predict_df])\n",
    "\n",
    "print(\"‚úÖ Missing values have been filled with predictions.\")\n",
    "\n",
    "\n",
    "# --- Part 6: Verify the Result ---\n",
    "missing_after_fill = final_df['CarbonEmissions'].isnull().sum()\n",
    "\n",
    "print(\"\\n--- Verification ---\")\n",
    "if missing_after_fill == 0:\n",
    "    print(\"üéâ Success! There are now 0 missing carbon emission values.\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Something went wrong. There are still {missing_after_fill} missing values.\")\n",
    "\n",
    "# Save our completed dataset to a new file for Week 4\n",
    "final_df.to_csv('companies_with_full_emissions_data.csv', index=False)\n",
    "print(\"‚úÖ Final, completed dataset saved to 'companies_with_full_emissions_data.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
